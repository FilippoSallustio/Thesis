{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTSE MIB Forecasting\n",
    "\n",
    "This repository demonstrates how to forecast the FTSE MIB index using\n",
    "an LSTM-based neural network.\n",
    "The data is provided in `dataftsemib_manual.csv`.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Install the required Python packages:\n",
    "\n",
    "```bash\n",
    "pip install pandas matplotlib scikit-learn tensorflow==2.12.0 statsmodels pmdarima\n",
    "```\n",
    "\n",
    "## Dataset summary\n",
    "\n",
    "Basic descriptive statistics for `dataftsemib_manual.csv`:\n",
    "\n",
    "|       |    Price |     Open |     High |      Low |           Vol. |   Change % |\n",
    "|:------|---------:|---------:|---------:|---------:|---------------:|-----------:|\n",
    "| count |  2810    |  2810    |  2810    |  2810    | 2793           |    2810    |\n",
    "| mean  | 21626.3  | 21633    | 21788.8  | 21458.9  | 5.80479e+08    |       0.03 |\n",
    "| std   |  3311.02 |  3307.02 |  3300.54 |  3313.23 | 2.7726e+08     |       1.42 |\n",
    "| min   | 14894.4  | 14985.8  | 15267.8  | 14153.1  | 2.67e+06       |     -16.92 |\n",
    "| 25%   | 19255.6  | 19266.4  | 19405.1  | 19090.9  | 3.8366e+08    |      -0.65 |\n",
    "| 50%   | 21556.4  | 21544.2  | 21700.7  | 21395.5  | 4.9929e+08    |       0.08 |\n",
    "| 75%   | 23607.7  | 23613.4  | 23759.6  | 23435.6  | 7.142e+08     |       0.78 |\n",
    "| max   | 30426.6  | 30595    | 30652.9  | 30341.2  | 2.68e+09      |       8.93 |\n",
    "\n",
    "## Running the LSTM example\n",
    "\n",
    "Execute the LSTM script to clean the data, train the model and produce a\n",
    "one-step ahead forecast.  By default the script expects\n",
    "`dataftsemib_manual.csv`, but you can specify a different file with\n",
    "`--data`.  You can also adjust the sequence window, batch size and\n",
    "learning rate:\n",
    "\n",
    "```bash\n",
    "python3 ftse_mib_LSTM.py --epochs 100 --window 60 --batch 32\n",
    "python3 ftse_mib_LSTM.py --data mydata.csv --lr 0.0005\n",
    "```\n",
    "\n",
    "If running inside Jupyter, ipykernel will pass additional command line\n",
    "arguments.  The script ignores these using `parse_known_args`, so it can be\n",
    "invoked with e.g. `!python ftse_mib_LSTM.py` inside a notebook without\n",
    "raising `SystemExit` errors.\n",
    "\n",
    "The script now uses several features (open, high, low, volume and a\n",
    "5-day moving average) and feeds sequences of the last `--window` days\n",
    "into a deeper LSTM network with dropout and learning rate scheduling.\n",
    "Training stops automatically when the validation loss fails to improve\n",
    "for several epochs.  Two plots\n",
    "are saved and displayed:\n",
    "\n",
    "- `closing_price_plot.png` – the cleaned closing prices\n",
    "- `lstm_prediction_plot.png` – actual vs. predicted test prices\n",
    "\n",
    "A trained model file `ftse_mib_lstm_model.h5` is saved along with the\n",
    "best weights during training (`best_lstm.h5`).\n",
    "\n",
    "## Feedforward ANN example\n",
    "\n",
    "For a simpler neural approach without recurrent layers you can run the\n",
    "ANN script.  It uses only the past 60 closing prices as inputs to a\n",
    "multi-layer perceptron and forecasts the next day's close.\n",
    "\n",
    "```bash\n",
    "python3 ftse_mib_ann.py\n",
    "```\n",
    "\n",
    "The script scales the closing prices using `MinMaxScaler`, splits the\n",
    "series into an 80/20 train/test split and trains a small network of\n",
    "Dense layers with early stopping.  It prints RMSE, MAE, MAPE and R² on\n",
    "the test portion and reports a residual Ljung–Box p-value to check for\n",
    "autocorrelation.  Two figures are saved: `ann_prediction_plot.png`\n",
    "showing actual versus predicted prices and `ann_residuals.png` with the\n",
    "residual distribution.  The trained model is saved to\n",
    "`ftse_mib_ann_model.h5`.\n",
    "\n",
    "## ARIMA example\n",
    "\n",
    "For a simple statistical baseline you can also run:\n",
    "\n",
    "```bash\n",
    "python3 ftse_mib_arima.py\n",
    "```\n",
    "\n",
    "This script displays and saves several diagnostic plots including the cleaned closing\n",
    "prices (`arima_cleaned_prices.png`) as well as ACF/PACF graphs\n",
    "(`arima_acf_pacf.png`). It then fits an ARIMA model selected via a small grid\n",
    "search and produces a rolling one-step forecast to compare against the test\n",
    "data. The series is split 80/20 between training and test portions. The results\n",
    "are saved to `arima_prediction_plot.png`. If the residuals of the initial model\n",
    "exhibit autocorrelation (Ljung-Box p < 0.05), the script automatically\n",
    "re-estimates an ARIMA(3,1,3) model for comparison.\n",
    "\n",
    "## XGBoost example\n",
    "\n",
    "For a gradient boosting approach you can run an XGBoost model that forecasts\n",
    "the next day's *log variance* using a large set of lagged return and volatility\n",
    "features:\n",
    "\n",
    "```bash\n",
    "python3 ftse_mib_xgboost.py\n",
    "```\n",
    "\n",
    "The script constructs rolling statistics, range-based measures and technical\n",
    "indicators, then tunes hyperparameters with a randomised search. Accuracy is\n",
    "reported with RMSE, MAE, MAPE, $R^2$, QLIKE, directional accuracy and a\n",
    "Ljung‑Box test on the residuals. The ten most important features are listed.\n",
    "The high‑resolution plot `xgb_variance_prediction.png` compares the predicted\n",
    "and actual log variance on the test set.\n",
    "\n",
    "\n",
    "## EGARCH example\n",
    "\n",
    "To model the volatility of daily returns you can run the EGARCH\n",
    "script:\n",
    "\n",
    "```bash\n",
    "python3 ftse_mib_egarch.py\n",
    "```\n",
    "\n",
    "The script calculates log returns and incorporates log volume together\n",
    "with lagged realised variance and past shocks as exogenous regressors.\n",
    "After checking stationarity and ARCH effects it searches a few EGARCH\n",
    "orders using Student's *t* and GED distributions.  The model forecasts\n",
    "the next day's **log variance** (log of the squared return).  An 80/20\n",
    "chronological split is evaluated and metrics including RMSE, MAE, MAPE,\n",
    "$R^2$, QLIKE and directional accuracy are printed along with residual\n",
    "statistics. Forecasts are saved as `egarch_variance_plot.png` together\n",
    "with the model's AIC, BIC, log-likelihood and a Ljung-Box diagnostic.\n",
    "\n",
    "## GJR-GARCH example\n",
    "\n",
    "The threshold GARCH script cleans the dataset and computes log\n",
    "returns.  Log volume, lagged realised variance and past shocks serve as\n",
    "exogenous regressors.  A small grid search over `(p,o,q)` orders and\n",
    "Student's *t* or GED distributions selects the model with the lowest\n",
    "AIC.  Forecasts target the next day's **log variance** of returns.  An\n",
    "80/20 split is used for evaluation with the same metrics as EGARCH and\n",
    "residual diagnostics.\n",
    "\n",
    "Run\n",
    "\n",
    "```bash\n",
    "python3 ftse_mib_gjrgarch.py\n",
    "```\n",
    "\n",
    "The script saves a high-resolution plot `gjrgarch_variance_plot.png` showing\n",
    "actual versus predicted log variance and prints the same residual statistics\n",
    "and information criteria as the EGARCH example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML table saved as 'ftse_mib_snapshot.html'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned FTSE MIB dataset\n",
    "df = pd.read_csv('dataftsemib_manual.csv', parse_dates=['Date'])\n",
    "\n",
    "show_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']\n",
    "\n",
    "# Get first 5 and last 2 rows\n",
    "snapshot = pd.concat([df[show_cols].head(5), df[show_cols].tail(2)]).copy()\n",
    "\n",
    "# Ensure all numeric columns are properly converted before formatting\n",
    "for col in ['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']:\n",
    "    # Remove potential formatting and convert to float\n",
    "    snapshot[col] = pd.to_numeric(snapshot[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.replace('%', ''), errors='coerce')\n",
    "    # Now format as string with 2 decimals\n",
    "    snapshot[col] = snapshot[col].apply(lambda x: f\"{x:,.2f}\" if pd.notnull(x) else \"\")\n",
    "\n",
    "# Write the HTML table\n",
    "snapshot.to_html(\n",
    "    \"ftse_mib_snapshot.html\",\n",
    "    index=False,\n",
    "    border=1,\n",
    "    justify='center'\n",
    ")\n",
    "\n",
    "print(\"HTML table saved as 'ftse_mib_snapshot.html'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Date Price  Open  High   Low Change %\n",
      "  2/1/2013 16.89 16.58 16.89 16.57   381.00\n",
      "  3/1/2013 16.91 16.87 16.92 16.78    10.00\n",
      "  4/1/2013 16.96 16.90 16.97 16.80    30.00\n",
      "  7/1/2013 16.90 16.99 17.10 16.87   -38.00\n",
      "  8/1/2013 16.95 16.85 17.08 16.82    33.00\n",
      "       ...   ...   ...   ...   ...      ...\n",
      "28/12/2023 30.33 30.50 30.52 30.33   -30.00\n",
      "29/12/2023 30.35 30.38 30.48 30.32     7.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('dataftsemib_manual.csv', parse_dates=['Date'])\n",
    "\n",
    "show_cols = ['Date', 'Price', 'Open', 'High', 'Low', 'Change %']\n",
    "\n",
    "# Function to clean and convert numeric columns\n",
    "def clean_to_float(s):\n",
    "    # Remove thousands separators, convert commas to dots, remove % signs, handle missing\n",
    "    if pd.isnull(s):\n",
    "        return None\n",
    "    s = str(s).replace('.', '').replace(',', '.').replace('%', '').strip()\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "for col in ['Price', 'Open', 'High', 'Low', 'Change %']:\n",
    "    df[col] = df[col].apply(clean_to_float)\n",
    "\n",
    "# Get first 5 and last 2 rows\n",
    "first_rows = df[show_cols].head(5)\n",
    "last_rows = df[show_cols].tail(2)\n",
    "\n",
    "# Format numbers for neat display (2 decimals)\n",
    "for col in ['Price', 'Open', 'High', 'Low', 'Change %']:\n",
    "    first_rows[col] = first_rows[col].apply(lambda x: f\"{x:,.2f}\" if pd.notnull(x) else \"\")\n",
    "    last_rows[col] = last_rows[col].apply(lambda x: f\"{x:,.2f}\" if pd.notnull(x) else \"\")\n",
    "\n",
    "# Create the ellipsis row\n",
    "ellipsis_row = pd.DataFrame([['...'] * len(show_cols)], columns=show_cols)\n",
    "\n",
    "# Combine for snapshot\n",
    "snapshot = pd.concat([first_rows, ellipsis_row, last_rows], ignore_index=True)\n",
    "\n",
    "# Print as plain text table for easy copying into Word/Docs/LaTeX\n",
    "print(snapshot.to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
